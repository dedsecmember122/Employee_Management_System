{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12045e22-e3e4-486e-ba30-9aef73e68eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.120 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.70  Python-3.11.7 torch-2.5.1+cpu CPU (AMD Ryzen 7 5800H with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11l.pt, data=C:\\Users\\HP\\Desktop\\Machine learning\\custom__dataset\\data.yaml, epochs=100, time=None, patience=100, batch=12, imgsz=84, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train4\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 23        [16, 19, 22]  1   1411795  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "YOLO11l summary: 631 layers, 25,311,251 parameters, 25,311,235 gradients, 87.3 GFLOPs\n",
      "\n",
      "Transferred 1009/1015 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train4', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "WARNING  imgsz=[84] must be multiple of max stride 32, updating to [96]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\HP\\Desktop\\Machine learning\\custom__dataset\\train\\labels.cache... 516 images, 3495 backgrounds, 0 corrupt: 100%|██████████| 4011/4011 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\HP\\Desktop\\Machine learning\\custom__dataset\\valid\\labels.cache... 49 images, 367 backgrounds, 0 corrupt: 100%|██████████| 416/416 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train4\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.00046875), 173 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 96 train, 96 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train4\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100         0G      1.299      1.615       1.42          4         96: 100%|██████████| 335/335 [03:41<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50    0.00244       0.98     0.0052    0.00396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100         0G      1.415      1.731      1.493          1         96: 100%|██████████| 335/335 [03:29<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.571       0.24      0.406       0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100         0G        1.3      1.571      1.416          0         96: 100%|██████████| 335/335 [03:23<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.321        0.5       0.28     0.0871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100         0G       1.25      1.561      1.385          1         96: 100%|██████████| 335/335 [03:18<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.881       0.84      0.861      0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100         0G      1.194      1.413       1.35          1         96: 100%|██████████| 335/335 [03:21<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.945       0.84      0.888       0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100         0G      1.173      1.276      1.347          2         96: 100%|██████████| 335/335 [03:12<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.954       0.84      0.885      0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100         0G      1.085      1.178      1.272          2         96: 100%|██████████| 335/335 [03:19<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.872      0.816       0.81      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100         0G      1.069        1.1      1.273          0         96: 100%|██████████| 335/335 [03:21<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.984       0.88      0.939      0.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100         0G      1.018     0.9715      1.259          0         96: 100%|██████████| 335/335 [03:24<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.978      0.896      0.925      0.639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100         0G      1.021     0.9959      1.249          0         96: 100%|██████████| 335/335 [03:19<00:00,  1.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.384        0.3       0.27      0.195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100         0G      1.037      1.086      1.244          0         96: 100%|██████████| 335/335 [03:22<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.978      0.897      0.897      0.676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100         0G     0.9737     0.9715        1.2          3         96: 100%|██████████| 335/335 [03:24<00:00,  1.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.992       0.68      0.805      0.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100         0G     0.9924     0.9857      1.231          1         96: 100%|██████████| 335/335 [03:20<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.977      0.853      0.907      0.653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100         0G     0.9376     0.8176      1.207          3         96: 100%|██████████| 335/335 [03:31<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.998        0.9      0.941      0.665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100         0G     0.9151     0.8656      1.189          1         96: 100%|██████████| 335/335 [03:22<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.974        0.9      0.929       0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100         0G     0.9304     0.9004       1.18          0         96: 100%|██████████| 335/335 [03:30<00:00,  1.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.994        0.9      0.897      0.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100         0G       0.94     0.8295      1.216          3         96: 100%|██████████| 335/335 [03:29<00:00,  1.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.974        0.9      0.926      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100         0G     0.9132     0.8082      1.181          1         96: 100%|██████████| 335/335 [03:16<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.979      0.931      0.936      0.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100         0G     0.8871     0.8922      1.173          1         96: 100%|██████████| 335/335 [03:10<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.996        0.9       0.93      0.668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100         0G     0.9094     0.7884      1.178          2         96: 100%|██████████| 335/335 [03:46<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.998        0.9      0.932      0.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100         0G     0.9016      0.752      1.189          1         96: 100%|██████████| 335/335 [03:09<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.997       0.92      0.917      0.674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100         0G     0.8552     0.7544       1.17          0         96: 100%|██████████| 335/335 [03:10<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.917      0.935      0.712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100         0G     0.8537     0.7679      1.159          0         96: 100%|██████████| 335/335 [03:15<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.994        0.9      0.953      0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100         0G     0.8742     0.7454       1.18          2         96: 100%|██████████| 335/335 [03:16<00:00,  1.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.917      0.927      0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100         0G     0.8696     0.7349      1.187          0         96: 100%|██████████| 335/335 [03:37<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:10<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.998        0.9      0.946      0.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100         0G     0.8752     0.7597      1.161          0         96: 100%|██████████| 335/335 [03:32<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.919      0.936      0.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100         0G     0.8098     0.7174      1.141          0         96: 100%|██████████| 335/335 [03:10<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.916      0.937      0.689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100         0G     0.7789     0.6975      1.135          3         96: 100%|██████████| 335/335 [03:18<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.918      0.952      0.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100         0G     0.8006     0.6967      1.135          3         96: 100%|██████████| 335/335 [03:14<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.917      0.937      0.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100         0G     0.7951     0.6877      1.122          2         96: 100%|██████████| 335/335 [03:09<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1       0.92       0.96      0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100         0G     0.8063     0.6771      1.136          2         96: 100%|██████████| 335/335 [03:09<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.937      0.955      0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100         0G     0.8039     0.6294      1.144          0         96: 100%|██████████| 335/335 [03:09<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.959      0.936      0.952      0.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100         0G     0.7765     0.6222      1.138          1         96: 100%|██████████| 335/335 [03:08<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.998        0.9      0.947       0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100         0G     0.7332     0.6762      1.081          1         96: 100%|██████████| 335/335 [03:08<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.996       0.94      0.936      0.709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100         0G     0.7625     0.6171      1.114          1         96: 100%|██████████| 335/335 [03:12<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.996       0.96      0.957      0.703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100         0G     0.7611      0.595      1.125          2         96: 100%|██████████| 335/335 [03:12<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.997        0.9      0.951      0.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100         0G     0.7466     0.6123      1.127          1         96: 100%|██████████| 335/335 [03:13<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.998        0.9      0.932      0.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100         0G     0.7334     0.6099      1.096          2         96: 100%|██████████| 335/335 [03:12<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.997        0.9      0.923      0.729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100         0G      0.755     0.6229      1.092          1         96: 100%|██████████| 335/335 [03:07<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.953       0.96      0.954        0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100         0G     0.6849     0.5613      1.067          0         96: 100%|██████████| 335/335 [03:08<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.938      0.955      0.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100         0G     0.7055     0.5751      1.079          2         96: 100%|██████████| 335/335 [03:07<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.959      0.956      0.697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100         0G      0.759     0.6022      1.128          2         96: 100%|██████████| 335/335 [03:07<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.939      0.974      0.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100         0G     0.6965      0.564      1.078          1         96: 100%|██████████| 335/335 [03:08<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.999       0.94      0.972      0.717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100         0G     0.7198     0.5581      1.086          2         96: 100%|██████████| 335/335 [03:08<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1       0.94      0.946      0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100         0G     0.7398     0.6141      1.109          1         96: 100%|██████████| 335/335 [03:08<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.979      0.933      0.952      0.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100         0G      0.702     0.5461      1.092          3         96: 100%|██████████| 335/335 [03:08<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.994       0.96      0.955      0.715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100         0G     0.7085     0.5638      1.099          2         96: 100%|██████████| 335/335 [03:08<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.938      0.954      0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100         0G     0.6861     0.5333      1.069          2         96: 100%|██████████| 335/335 [03:09<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.956      0.955      0.789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100         0G     0.6847     0.5413      1.076          1         96: 100%|██████████| 335/335 [03:15<00:00,  1.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.959      0.955       0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100         0G     0.6899     0.5609      1.081          1         96: 100%|██████████| 335/335 [03:10<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50       0.98      0.957      0.955      0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100         0G     0.6729     0.5191      1.083          0         96: 100%|██████████| 335/335 [03:20<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.976       0.94      0.938      0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100         0G     0.6649     0.5177      1.064          0         96: 100%|██████████| 335/335 [03:09<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.939      0.974      0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100         0G     0.6565     0.5003      1.067          1         96: 100%|██████████| 335/335 [03:14<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.939      0.955      0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100         0G     0.6558     0.5296       1.06          1         96: 100%|██████████| 335/335 [03:35<00:00,  1.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.939      0.966      0.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100         0G     0.6495     0.5041      1.043          0         96: 100%|██████████| 335/335 [03:10<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.956      0.956      0.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100         0G     0.6365      0.501      1.054          0         96: 100%|██████████| 335/335 [03:21<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:09<00:00,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.959      0.956      0.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100         0G     0.6864     0.4968      1.075          0         96: 100%|██████████| 335/335 [03:06<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.958      0.956      0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100         0G     0.6364     0.4956      1.062          1         96: 100%|██████████| 335/335 [03:07<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.999       0.96      0.974       0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100         0G      0.664     0.4579      1.069          0         96: 100%|██████████| 335/335 [03:05<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.996       0.96      0.975      0.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100         0G     0.6504     0.4723      1.065          1         96: 100%|██████████| 335/335 [03:06<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.959      0.956      0.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100         0G     0.6757     0.4783      1.069          3         96: 100%|██████████| 335/335 [03:07<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.959      0.956      0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100         0G     0.6809     0.4986      1.068          1         96: 100%|██████████| 335/335 [03:05<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.996       0.96      0.956       0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100         0G     0.6102     0.4506      1.054          0         96: 100%|██████████| 335/335 [03:05<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.956      0.956      0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100         0G     0.6184     0.4793      1.023          0         96: 100%|██████████| 335/335 [03:06<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.939      0.955      0.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100         0G     0.6125     0.4483       1.04          0         96: 100%|██████████| 335/335 [03:06<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.998       0.96      0.956      0.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100         0G     0.6251     0.4621      1.058          1         96: 100%|██████████| 335/335 [03:06<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.999       0.96      0.956      0.785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100         0G      0.608     0.4391       1.06          1         96: 100%|██████████| 335/335 [03:06<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.976      0.976      0.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100         0G     0.6136     0.5131      1.033          4         96: 100%|██████████| 335/335 [03:05<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1       0.96      0.976      0.774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100         0G     0.6422     0.4885      1.062          1         96: 100%|██████████| 335/335 [03:05<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.999       0.96       0.96      0.789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100         0G     0.6129     0.4386      1.037          0         96: 100%|██████████| 335/335 [03:06<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.959      0.958      0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100         0G     0.5991     0.4319      1.047          0         96: 100%|██████████| 335/335 [03:07<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.996       0.96      0.956      0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100         0G     0.6534      0.467      1.079          1         96: 100%|██████████| 335/335 [03:06<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.958      0.956      0.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100         0G     0.6134      0.429      1.048          1         96: 100%|██████████| 335/335 [03:06<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.959      0.957      0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100         0G     0.5797     0.4299      1.019          0         96: 100%|██████████| 335/335 [03:06<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.975      0.976      0.789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100         0G     0.6069     0.4124      1.042          2         96: 100%|██████████| 335/335 [03:06<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.999       0.98       0.98      0.794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100         0G      0.586     0.4311      1.036          2         96: 100%|██████████| 335/335 [03:06<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50       0.98       0.98      0.978      0.791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100         0G     0.5621     0.3981      1.025          0         96: 100%|██████████| 335/335 [03:06<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.999       0.98      0.977      0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100         0G     0.5929     0.4412       1.04          1         96: 100%|██████████| 335/335 [03:06<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.977       0.96      0.955      0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100         0G     0.5831     0.4375      1.028          0         96: 100%|██████████| 335/335 [03:06<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.999       0.94      0.955      0.782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100         0G     0.5743     0.3903      1.037          1         96: 100%|██████████| 335/335 [03:06<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1       0.96      0.957      0.774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100         0G     0.5902     0.4109      1.038          0         96: 100%|██████████| 335/335 [03:06<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.955      0.958      0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100         0G     0.5877     0.3992      1.038          0         96: 100%|██████████| 335/335 [03:06<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.998       0.96      0.956      0.773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100         0G     0.5556     0.3951      1.032          2         96: 100%|██████████| 335/335 [03:06<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.999       0.96      0.956      0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100         0G     0.5488     0.3795      1.027          2         96: 100%|██████████| 335/335 [03:06<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.998       0.96      0.957      0.774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100         0G     0.5891     0.4074      1.031          0         96: 100%|██████████| 335/335 [03:05<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.957      0.975      0.777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100         0G      0.573     0.4287      1.031          0         96: 100%|██████████| 335/335 [03:06<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.997       0.96      0.956      0.774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100         0G     0.5673     0.3831      1.034          0         96: 100%|██████████| 335/335 [03:05<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1       0.96      0.956      0.774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100         0G     0.5604     0.4108      1.019          0         96: 100%|██████████| 335/335 [03:05<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.997       0.96      0.975      0.783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100         0G      0.561      0.395      1.025          1         96: 100%|██████████| 335/335 [03:05<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50      0.979       0.98      0.975      0.779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100         0G     0.5547     0.3625      1.018          0         96: 100%|██████████| 335/335 [03:05<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.938      0.955      0.786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100         0G     0.3451     0.1908     0.9005          1         96: 100%|██████████| 335/335 [03:04<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.938      0.972      0.811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100         0G     0.3322     0.1785      0.873          0         96: 100%|██████████| 335/335 [03:04<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.938      0.971      0.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100         0G     0.3228      0.169     0.8474          1         96: 100%|██████████| 335/335 [03:04<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.938      0.972      0.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100         0G     0.3055     0.1606     0.8282          0         96: 100%|██████████| 335/335 [03:04<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.939      0.972      0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100         0G     0.3188     0.1657     0.8604          0         96: 100%|██████████| 335/335 [03:03<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.939      0.972      0.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100         0G     0.2839     0.1488     0.8245          0         96: 100%|██████████| 335/335 [03:03<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.959      0.974      0.819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100         0G     0.2917     0.1487     0.8236          0         96: 100%|██████████| 335/335 [03:03<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.956      0.974      0.824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100         0G     0.3278     0.1646     0.8755          1         96: 100%|██████████| 335/335 [03:04<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.939      0.974      0.822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100         0G     0.3119     0.1656     0.8752          0         96: 100%|██████████| 335/335 [03:03<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.956      0.975      0.829\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100         0G     0.3007     0.1518     0.8226          0         96: 100%|██████████| 335/335 [03:04<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:08<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.939      0.975      0.824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 epochs completed in 5.625 hours.\n",
      "Optimizer stripped from runs\\detect\\train4\\weights\\last.pt, 51.1MB\n",
      "Optimizer stripped from runs\\detect\\train4\\weights\\best.pt, 51.1MB\n",
      "\n",
      "Validating runs\\detect\\train4\\weights\\best.pt...\n",
      "Ultralytics 8.3.70  Python-3.11.7 torch-2.5.1+cpu CPU (AMD Ryzen 7 5800H with Radeon Graphics)\n",
      "YOLO11l summary (fused): 464 layers, 25,280,083 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:07<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        416         50          1      0.956      0.975      0.828\n",
      "Speed: 0.0ms preprocess, 16.9ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train4\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001E65E319090>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.76798,     0.74829,      0.7286,     0.70891,     0.68921,     0.66952,\n",
       "            0.64983,     0.63014,     0.61045,     0.59075,     0.57106,     0.55137,     0.53168,     0.51199,      0.4923,      0.4726,     0.45291,     0.43322,     0.41353,     0.39384,     0.37414,     0.35445,     0.33476,     0.31507,     0.29538,     0.27569,     0.25599,      0.2363,     0.21661,\n",
       "            0.19692,     0.17723,     0.15753,     0.13784,     0.11815,    0.098459,    0.078767,    0.059075,    0.039384,    0.019692,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.86486,     0.86486,     0.89859,      0.9028,     0.90701,     0.91123,     0.91464,     0.91595,     0.91725,     0.91855,     0.91985,     0.92115,     0.92244,     0.92341,     0.92406,     0.92472,     0.92537,     0.92602,     0.92667,     0.92732,     0.92797,     0.92862,     0.92927,\n",
       "            0.92991,     0.93056,      0.9312,     0.93185,     0.93229,     0.93265,       0.933,     0.93336,     0.93371,     0.93407,     0.93442,     0.93477,     0.93513,     0.93548,     0.93584,     0.93619,     0.93654,     0.93689,     0.93725,      0.9376,     0.93795,      0.9383,     0.93865,\n",
       "              0.939,     0.93936,     0.93971,     0.94006,     0.94041,     0.94076,     0.94111,     0.94163,     0.94221,     0.94278,     0.94335,     0.94392,     0.94449,     0.94506,     0.94563,      0.9462,     0.94677,     0.94733,      0.9479,     0.94846,     0.94903,     0.94959,     0.95016,\n",
       "            0.95051,     0.95055,      0.9506,     0.95064,     0.95068,     0.95072,     0.95076,      0.9508,     0.95085,     0.95089,     0.95093,     0.95097,     0.95101,     0.95106,      0.9511,     0.95114,     0.95118,     0.95122,     0.95127,     0.95131,     0.95135,     0.95139,     0.95143,\n",
       "            0.95147,     0.95152,     0.95156,      0.9516,     0.95164,     0.95168,     0.95172,     0.95177,     0.95181,     0.95185,     0.95189,     0.95193,     0.95198,     0.95202,     0.95206,      0.9521,     0.95214,     0.95218,     0.95223,     0.95227,     0.95231,     0.95235,     0.95239,\n",
       "            0.95243,     0.95248,     0.95252,     0.95256,      0.9526,     0.95264,     0.95268,     0.95273,     0.95277,     0.95281,     0.95285,     0.95289,     0.95293,     0.95298,     0.95302,     0.95306,      0.9531,     0.95314,     0.95318,     0.95323,     0.95327,     0.95331,     0.95335,\n",
       "            0.95339,     0.95343,     0.95348,     0.95352,     0.95356,      0.9536,     0.95364,     0.95368,     0.95373,     0.95377,     0.95381,     0.95385,     0.95389,     0.95393,     0.95398,     0.95402,     0.95406,      0.9541,     0.95414,     0.95418,     0.95423,     0.95427,     0.95431,\n",
       "            0.95435,     0.95439,     0.95443,     0.95447,     0.95452,     0.95456,      0.9546,     0.95464,     0.95468,     0.95472,     0.95477,     0.95481,     0.95485,     0.95489,     0.95493,     0.95497,     0.95501,     0.95506,      0.9551,     0.95514,     0.95518,     0.95522,     0.95526,\n",
       "             0.9553,     0.95535,     0.95539,     0.95543,     0.95547,     0.95551,     0.95555,     0.95559,     0.95564,     0.95568,     0.95572,     0.95576,      0.9558,     0.95584,     0.95588,     0.95593,     0.95597,     0.95601,     0.95605,     0.95609,     0.95613,     0.95617,     0.95622,\n",
       "            0.95626,      0.9563,     0.95634,     0.95638,     0.95642,     0.95646,     0.95651,     0.95655,     0.95659,     0.95663,     0.95667,     0.95671,     0.95675,      0.9568,     0.95684,     0.95688,     0.95692,     0.95696,       0.957,     0.95704,     0.95708,     0.95713,     0.95717,\n",
       "            0.95721,     0.95725,     0.95729,     0.95733,     0.95737,     0.95741,     0.95746,      0.9575,     0.95754,     0.95758,     0.95762,     0.95766,      0.9577,     0.95775,     0.95779,     0.95783,     0.95787,     0.95791,     0.95795,     0.95799,     0.95803,     0.95808,     0.95812,\n",
       "            0.95816,      0.9582,     0.95824,     0.95828,     0.95832,     0.95836,      0.9584,     0.95845,     0.95849,     0.95853,     0.95857,     0.95861,     0.95865,     0.95869,     0.95873,     0.95878,     0.95882,     0.95886,      0.9589,     0.95894,     0.95898,     0.95902,     0.95906,\n",
       "             0.9591,     0.95915,     0.95919,     0.95923,     0.95927,     0.95931,     0.95935,     0.95939,     0.95943,     0.95948,     0.95952,     0.95956,      0.9596,     0.95964,     0.95968,     0.95972,     0.95976,      0.9598,     0.95984,     0.95989,     0.95993,     0.95997,     0.96004,\n",
       "            0.96023,     0.96041,     0.96059,     0.96078,     0.96096,     0.96114,     0.96133,     0.96151,     0.96169,     0.96188,     0.96206,     0.96224,     0.96243,     0.96261,     0.96279,     0.96298,     0.96316,     0.96334,     0.96353,     0.96371,     0.96389,     0.96407,     0.96426,\n",
       "            0.96444,     0.96462,      0.9648,     0.96498,     0.96517,     0.96535,     0.96553,     0.96571,     0.96589,     0.96608,     0.96626,     0.96644,     0.96662,      0.9668,     0.96698,     0.96717,     0.96735,     0.96753,     0.96771,     0.96789,     0.96807,     0.96825,     0.96843,\n",
       "            0.96861,     0.96879,     0.96898,     0.96916,     0.96934,     0.96952,      0.9697,     0.96999,     0.97027,     0.97056,     0.97085,     0.97113,     0.97142,     0.97171,     0.97199,     0.97228,     0.97257,     0.97285,     0.97314,     0.97342,     0.97371,       0.974,     0.97428,\n",
       "            0.97457,     0.97485,     0.97514,     0.97542,      0.9757,     0.97599,     0.97627,     0.97656,     0.97684,     0.97712,     0.97741,     0.97769,     0.97797,     0.97825,     0.97854,     0.97882,      0.9791,     0.97938,     0.97957,     0.97948,      0.9794,     0.97931,     0.97923,\n",
       "            0.97914,     0.97906,     0.97897,     0.97889,      0.9788,     0.97871,     0.97863,     0.97854,     0.97846,     0.97837,     0.97829,      0.9782,     0.97811,     0.97803,     0.97794,     0.97786,     0.97777,     0.97769,      0.9776,     0.97751,     0.97743,     0.97734,     0.97726,\n",
       "            0.97717,     0.97709,       0.977,     0.97691,     0.97683,     0.97674,     0.97666,     0.97657,     0.97648,      0.9764,     0.97631,     0.97623,     0.97614,     0.97605,     0.97597,     0.97588,      0.9758,     0.97571,     0.97562,     0.97554,     0.97545,     0.97537,     0.97528,\n",
       "            0.97519,     0.97511,     0.97502,     0.97494,     0.97485,     0.97476,     0.97468,     0.97459,      0.9745,     0.97442,     0.97433,     0.97424,     0.97416,     0.97407,     0.97399,      0.9739,     0.97381,     0.97373,     0.97364,     0.97355,     0.97347,     0.97338,     0.97329,\n",
       "            0.97321,     0.97312,     0.97303,     0.97295,     0.97286,     0.97278,     0.97269,      0.9726,     0.97252,     0.97243,     0.97234,     0.97226,     0.97217,     0.97208,       0.972,     0.97191,     0.97182,     0.97174,     0.97165,     0.97156,     0.97148,     0.97139,      0.9713,\n",
       "            0.97121,     0.97113,     0.97104,     0.97095,     0.97087,     0.97078,     0.97069,     0.97061,     0.97052,     0.97043,     0.97035,     0.97026,     0.97017,     0.97008,        0.97,     0.96991,     0.96982,     0.96974,     0.96965,     0.96956,     0.96947,     0.96939,      0.9693,\n",
       "            0.96921,     0.96913,     0.96906,     0.96902,     0.96899,     0.96895,     0.96892,     0.96888,     0.96885,     0.96881,     0.96878,     0.96874,      0.9687,     0.96867,     0.96863,      0.9686,     0.96856,     0.96853,     0.96849,     0.96846,     0.96842,     0.96839,     0.96835,\n",
       "            0.96832,     0.96828,     0.96824,     0.96821,     0.96817,     0.96814,      0.9681,     0.96807,     0.96803,       0.968,     0.96796,     0.96793,     0.96789,     0.96785,     0.96782,     0.96778,     0.96775,     0.96771,     0.96768,     0.96764,     0.96761,     0.96757,     0.96753,\n",
       "             0.9675,     0.96746,     0.96743,     0.96739,     0.96736,     0.96732,     0.96729,     0.96725,     0.96722,     0.96718,     0.96714,     0.96711,     0.96707,     0.96704,       0.967,     0.96697,     0.96693,      0.9669,     0.96686,     0.96682,     0.96679,     0.96675,     0.96672,\n",
       "            0.96668,     0.96665,     0.96661,     0.96658,     0.96654,      0.9665,     0.96647,     0.96643,      0.9664,     0.96636,     0.96633,     0.96629,     0.96626,     0.96622,     0.96618,     0.96615,     0.96611,     0.96608,     0.96604,     0.96601,     0.96597,     0.96594,      0.9659,\n",
       "            0.96586,     0.96583,     0.96579,     0.96576,     0.96572,     0.96569,     0.96565,     0.96561,     0.96558,     0.96554,     0.96551,     0.96547,     0.96544,      0.9654,     0.96537,     0.96533,     0.96529,     0.96526,     0.96522,     0.96519,     0.96515,     0.96512,     0.96508,\n",
       "            0.96504,     0.96501,     0.96497,     0.96494,      0.9649,     0.96487,     0.96483,     0.96479,     0.96476,     0.96472,     0.96469,     0.96465,     0.96462,     0.96458,     0.96454,     0.96451,     0.96447,     0.96444,      0.9644,     0.96437,     0.96433,     0.96429,     0.96426,\n",
       "            0.96422,     0.96419,     0.96415,     0.96412,     0.96408,     0.96404,     0.96401,     0.96397,     0.96394,      0.9639,     0.96387,     0.96383,     0.96379,     0.96376,     0.96372,     0.96369,     0.96365,     0.96362,     0.96358,     0.96354,     0.96351,     0.96347,     0.96344,\n",
       "             0.9634,     0.96337,     0.96333,     0.96329,     0.96326,     0.96322,     0.96319,     0.96315,     0.96311,     0.96308,     0.96304,     0.96301,     0.96297,     0.96294,      0.9629,     0.96286,     0.96283,     0.96279,     0.96276,     0.96272,     0.96269,     0.96265,     0.96261,\n",
       "            0.96258,     0.96254,     0.96251,     0.96247,     0.96243,      0.9624,     0.96236,     0.96233,     0.96229,     0.96226,     0.96222,     0.96218,     0.96215,     0.96211,     0.96208,     0.96204,       0.962,     0.96197,     0.96193,      0.9619,     0.96186,     0.96182,     0.96179,\n",
       "            0.96175,     0.96172,     0.96168,     0.96165,     0.96161,     0.96157,     0.96154,      0.9615,     0.96147,     0.96143,     0.96139,     0.96136,     0.96132,     0.96129,     0.96125,     0.96121,     0.96118,     0.96114,     0.96111,     0.96107,     0.96103,       0.961,     0.96096,\n",
       "            0.96093,     0.96089,     0.96085,     0.96082,     0.96078,     0.96075,     0.96071,     0.96067,     0.96064,      0.9606,     0.96057,     0.96053,      0.9605,     0.96046,     0.96042,     0.96039,     0.96035,     0.96032,     0.96028,     0.96024,     0.96021,     0.96017,     0.96014,\n",
       "             0.9601,     0.96006,     0.96003,     0.95999,     0.95996,     0.95992,     0.95988,     0.95985,     0.95981,     0.95978,     0.95974,      0.9597,     0.95967,     0.95963,     0.95959,     0.95956,     0.95952,     0.95949,     0.95945,     0.95941,     0.95938,     0.95934,     0.95931,\n",
       "            0.95927,     0.95923,      0.9592,     0.95916,     0.95913,     0.95909,     0.95905,     0.95902,     0.95898,     0.95895,     0.95891,     0.95887,     0.95884,      0.9588,     0.95877,     0.95873,     0.95869,     0.95866,     0.95862,     0.95858,     0.95855,     0.95851,     0.95848,\n",
       "            0.95844,      0.9584,     0.95837,      0.9582,     0.95468,     0.95114,     0.94757,     0.94501,      0.9425,     0.93998,     0.93744,     0.93602,     0.93573,     0.93544,     0.93514,     0.93485,     0.93455,     0.93426,     0.93396,     0.93367,     0.93338,     0.93308,     0.93278,\n",
       "            0.93249,     0.93219,      0.9319,      0.9316,     0.93131,     0.93101,     0.93071,     0.93042,     0.93012,     0.92982,     0.92953,     0.92923,     0.92893,     0.92863,     0.92834,     0.92804,     0.92774,     0.92744,     0.92714,     0.92685,     0.92655,     0.92625,     0.92595,\n",
       "            0.92565,     0.92535,     0.92505,     0.92475,     0.92423,     0.92369,     0.92315,     0.92261,     0.92207,     0.92152,     0.92098,     0.92044,      0.9199,     0.91935,     0.91881,     0.91826,     0.91772,     0.91717,     0.91662,     0.91608,     0.91553,     0.91498,     0.91443,\n",
       "            0.91388,     0.91333,     0.91066,     0.90563,     0.90076,     0.89763,     0.89449,     0.89133,     0.87592,     0.87166,     0.86737,     0.85212,     0.82907,     0.81239,      0.7789,     0.76928,     0.75384,     0.74453,     0.73764,     0.71014,     0.69705,     0.68958,     0.66965,\n",
       "            0.62343,       0.588,     0.57999,     0.57189,     0.54361,     0.53287,     0.48287,     0.44906,     0.43431,     0.42573,     0.41707,     0.40943,     0.40284,      0.3962,      0.3895,     0.37845,     0.36482,     0.35637,     0.35019,     0.34397,      0.3377,     0.33004,     0.31929,\n",
       "             0.3084,     0.28123,     0.27387,     0.27151,     0.26914,     0.26677,     0.26439,       0.262,     0.25961,      0.2572,      0.2548,     0.25238,     0.24996,     0.24754,     0.24265,     0.22836,     0.21416,      0.2101,     0.20602,     0.20192,      0.1978,     0.19366,      0.1895,\n",
       "            0.18533,     0.17515,     0.14744,      0.1454,     0.14336,     0.14131,     0.13926,      0.1372,     0.13514,     0.13308,     0.13101,     0.12893,     0.12685,     0.12477,     0.12268,     0.12059,     0.11849,     0.11639,     0.11428,     0.07373,    0.066017,    0.058242,    0.050404,\n",
       "           0.042502,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.78689,     0.78689,     0.84457,     0.85204,     0.85956,     0.86717,     0.87337,     0.87576,     0.87815,     0.88054,     0.88293,     0.88532,     0.88771,      0.8895,     0.89072,     0.89193,     0.89315,     0.89437,     0.89558,      0.8968,     0.89801,     0.89923,     0.90044,\n",
       "            0.90166,     0.90287,     0.90409,      0.9053,     0.90613,     0.90681,     0.90748,     0.90815,     0.90882,      0.9095,     0.91017,     0.91084,     0.91151,     0.91219,     0.91286,     0.91353,      0.9142,     0.91487,     0.91555,     0.91622,     0.91689,     0.91756,     0.91824,\n",
       "            0.91891,     0.91958,     0.92025,     0.92092,      0.9216,     0.92227,     0.92294,     0.92396,     0.92506,     0.92617,     0.92727,     0.92837,     0.92948,     0.93058,     0.93168,     0.93279,     0.93389,       0.935,      0.9361,      0.9372,     0.93831,     0.93941,     0.94051,\n",
       "            0.94121,     0.94129,     0.94137,     0.94146,     0.94154,     0.94162,      0.9417,     0.94178,     0.94187,     0.94195,     0.94203,     0.94211,     0.94219,     0.94228,     0.94236,     0.94244,     0.94252,     0.94261,     0.94269,     0.94277,     0.94285,     0.94293,     0.94302,\n",
       "             0.9431,     0.94318,     0.94326,     0.94334,     0.94343,     0.94351,     0.94359,     0.94367,     0.94376,     0.94384,     0.94392,       0.944,     0.94408,     0.94417,     0.94425,     0.94433,     0.94441,     0.94449,     0.94458,     0.94466,     0.94474,     0.94482,     0.94491,\n",
       "            0.94499,     0.94507,     0.94515,     0.94523,     0.94532,      0.9454,     0.94548,     0.94556,     0.94564,     0.94573,     0.94581,     0.94589,     0.94597,     0.94606,     0.94614,     0.94622,      0.9463,     0.94638,     0.94647,     0.94655,     0.94663,     0.94671,     0.94679,\n",
       "            0.94688,     0.94696,     0.94704,     0.94712,     0.94721,     0.94729,     0.94737,     0.94745,     0.94753,     0.94762,      0.9477,     0.94778,     0.94786,     0.94794,     0.94803,     0.94811,     0.94819,     0.94827,     0.94836,     0.94844,     0.94852,      0.9486,     0.94868,\n",
       "            0.94877,     0.94885,     0.94893,     0.94901,     0.94909,     0.94918,     0.94926,     0.94934,     0.94942,     0.94951,     0.94959,     0.94967,     0.94975,     0.94983,     0.94992,        0.95,     0.95008,     0.95016,     0.95024,     0.95033,     0.95041,     0.95049,     0.95057,\n",
       "            0.95065,     0.95074,     0.95082,      0.9509,     0.95098,     0.95107,     0.95115,     0.95123,     0.95131,     0.95139,     0.95148,     0.95156,     0.95164,     0.95172,      0.9518,     0.95189,     0.95197,     0.95205,     0.95213,     0.95222,      0.9523,     0.95238,     0.95246,\n",
       "            0.95254,     0.95263,     0.95271,     0.95279,     0.95287,     0.95295,     0.95304,     0.95312,      0.9532,     0.95328,     0.95337,     0.95345,     0.95353,     0.95361,     0.95369,     0.95378,     0.95386,     0.95394,     0.95402,      0.9541,     0.95419,     0.95427,     0.95435,\n",
       "            0.95443,     0.95452,      0.9546,     0.95468,     0.95476,     0.95484,     0.95493,     0.95501,     0.95509,     0.95517,     0.95525,     0.95534,     0.95542,      0.9555,     0.95558,     0.95567,     0.95575,     0.95583,     0.95591,     0.95599,     0.95608,     0.95616,     0.95624,\n",
       "            0.95632,      0.9564,     0.95649,     0.95657,     0.95665,     0.95673,     0.95682,      0.9569,     0.95698,     0.95706,     0.95714,     0.95723,     0.95731,     0.95739,     0.95747,     0.95755,     0.95764,     0.95772,      0.9578,     0.95788,     0.95796,     0.95805,     0.95813,\n",
       "            0.95821,     0.95829,     0.95838,     0.95846,     0.95854,     0.95862,      0.9587,     0.95879,     0.95887,     0.95895,     0.95903,     0.95911,      0.9592,     0.95928,     0.95936,     0.95944,     0.95953,     0.95961,     0.95969,     0.95977,     0.95985,     0.95994,     0.96008,\n",
       "            0.96045,     0.96082,     0.96119,     0.96155,     0.96192,     0.96229,     0.96266,     0.96303,      0.9634,     0.96376,     0.96413,      0.9645,     0.96487,     0.96524,      0.9656,     0.96597,     0.96634,     0.96671,     0.96708,     0.96744,     0.96781,     0.96818,     0.96855,\n",
       "            0.96892,     0.96929,     0.96965,     0.97002,     0.97039,     0.97076,     0.97113,     0.97149,     0.97186,     0.97223,      0.9726,     0.97297,     0.97333,      0.9737,     0.97407,     0.97444,     0.97481,     0.97517,     0.97554,     0.97591,     0.97628,     0.97665,     0.97702,\n",
       "            0.97738,     0.97775,     0.97812,     0.97849,     0.97886,     0.97922,     0.97959,     0.98018,     0.98077,     0.98136,     0.98194,     0.98253,     0.98312,     0.98371,     0.98429,     0.98488,     0.98547,     0.98605,     0.98664,     0.98723,     0.98782,      0.9884,     0.98899,\n",
       "            0.98958,     0.99017,     0.99075,     0.99134,     0.99193,     0.99252,      0.9931,     0.99369,     0.99428,     0.99487,     0.99545,     0.99604,     0.99663,     0.99722,      0.9978,     0.99839,     0.99898,     0.99957,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[       0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,\n",
       "               0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,\n",
       "               0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,\n",
       "               0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,\n",
       "               0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,\n",
       "               0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,\n",
       "               0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,\n",
       "               0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,\n",
       "               0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,\n",
       "               0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,\n",
       "               0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,\n",
       "               0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,\n",
       "               0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,\n",
       "               0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,\n",
       "               0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,\n",
       "               0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,\n",
       "               0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,        0.96,     0.95996,     0.95979,     0.95963,     0.95946,      0.9593,\n",
       "            0.95914,     0.95897,     0.95881,     0.95864,     0.95848,     0.95832,     0.95815,     0.95799,     0.95782,     0.95766,      0.9575,     0.95733,     0.95717,       0.957,     0.95684,     0.95667,     0.95651,     0.95635,     0.95618,     0.95602,     0.95585,     0.95569,     0.95553,\n",
       "            0.95536,      0.9552,     0.95503,     0.95487,     0.95471,     0.95454,     0.95438,     0.95421,     0.95405,     0.95389,     0.95372,     0.95356,     0.95339,     0.95323,     0.95306,      0.9529,     0.95274,     0.95257,     0.95241,     0.95224,     0.95208,     0.95192,     0.95175,\n",
       "            0.95159,     0.95142,     0.95126,      0.9511,     0.95093,     0.95077,      0.9506,     0.95044,     0.95028,     0.95011,     0.94995,     0.94978,     0.94962,     0.94945,     0.94929,     0.94913,     0.94896,      0.9488,     0.94863,     0.94847,     0.94831,     0.94814,     0.94798,\n",
       "            0.94781,     0.94765,     0.94749,     0.94732,     0.94716,     0.94699,     0.94683,     0.94667,      0.9465,     0.94634,     0.94617,     0.94601,     0.94584,     0.94568,     0.94552,     0.94535,     0.94519,     0.94502,     0.94486,      0.9447,     0.94453,     0.94437,      0.9442,\n",
       "            0.94404,     0.94388,     0.94371,     0.94355,     0.94338,     0.94322,     0.94306,     0.94289,     0.94273,     0.94256,      0.9424,     0.94223,     0.94207,     0.94191,     0.94174,     0.94158,     0.94141,     0.94125,     0.94109,     0.94092,     0.94076,     0.94059,     0.94043,\n",
       "            0.94027,      0.9401,     0.93997,     0.93991,     0.93984,     0.93977,     0.93971,     0.93964,     0.93958,     0.93951,     0.93944,     0.93938,     0.93931,     0.93924,     0.93918,     0.93911,     0.93904,     0.93898,     0.93891,     0.93884,     0.93878,     0.93871,     0.93864,\n",
       "            0.93858,     0.93851,     0.93844,     0.93838,     0.93831,     0.93824,     0.93818,     0.93811,     0.93804,     0.93798,     0.93791,     0.93784,     0.93778,     0.93771,     0.93764,     0.93758,     0.93751,     0.93744,     0.93738,     0.93731,     0.93724,     0.93718,     0.93711,\n",
       "            0.93704,     0.93698,     0.93691,     0.93684,     0.93678,     0.93671,     0.93665,     0.93658,     0.93651,     0.93645,     0.93638,     0.93631,     0.93625,     0.93618,     0.93611,     0.93605,     0.93598,     0.93591,     0.93585,     0.93578,     0.93571,     0.93565,     0.93558,\n",
       "            0.93551,     0.93545,     0.93538,     0.93531,     0.93525,     0.93518,     0.93511,     0.93505,     0.93498,     0.93491,     0.93485,     0.93478,     0.93471,     0.93465,     0.93458,     0.93451,     0.93445,     0.93438,     0.93431,     0.93425,     0.93418,     0.93411,     0.93405,\n",
       "            0.93398,     0.93391,     0.93385,     0.93378,     0.93372,     0.93365,     0.93358,     0.93352,     0.93345,     0.93338,     0.93332,     0.93325,     0.93318,     0.93312,     0.93305,     0.93298,     0.93292,     0.93285,     0.93278,     0.93272,     0.93265,     0.93258,     0.93252,\n",
       "            0.93245,     0.93238,     0.93232,     0.93225,     0.93218,     0.93212,     0.93205,     0.93198,     0.93192,     0.93185,     0.93178,     0.93172,     0.93165,     0.93158,     0.93152,     0.93145,     0.93138,     0.93132,     0.93125,     0.93118,     0.93112,     0.93105,     0.93098,\n",
       "            0.93092,     0.93085,     0.93079,     0.93072,     0.93065,     0.93059,     0.93052,     0.93045,     0.93039,     0.93032,     0.93025,     0.93019,     0.93012,     0.93005,     0.92999,     0.92992,     0.92985,     0.92979,     0.92972,     0.92965,     0.92959,     0.92952,     0.92945,\n",
       "            0.92939,     0.92932,     0.92925,     0.92919,     0.92912,     0.92905,     0.92899,     0.92892,     0.92885,     0.92879,     0.92872,     0.92865,     0.92859,     0.92852,     0.92845,     0.92839,     0.92832,     0.92825,     0.92819,     0.92812,     0.92805,     0.92799,     0.92792,\n",
       "            0.92786,     0.92779,     0.92772,     0.92766,     0.92759,     0.92752,     0.92746,     0.92739,     0.92732,     0.92726,     0.92719,     0.92712,     0.92706,     0.92699,     0.92692,     0.92686,     0.92679,     0.92672,     0.92666,     0.92659,     0.92652,     0.92646,     0.92639,\n",
       "            0.92632,     0.92626,     0.92619,     0.92612,     0.92606,     0.92599,     0.92592,     0.92586,     0.92579,     0.92572,     0.92566,     0.92559,     0.92552,     0.92546,     0.92539,     0.92532,     0.92526,     0.92519,     0.92512,     0.92506,     0.92499,     0.92493,     0.92486,\n",
       "            0.92479,     0.92473,     0.92466,     0.92459,     0.92453,     0.92446,     0.92439,     0.92433,     0.92426,     0.92419,     0.92413,     0.92406,     0.92399,     0.92393,     0.92386,     0.92379,     0.92373,     0.92366,     0.92359,     0.92353,     0.92346,     0.92339,     0.92333,\n",
       "            0.92326,     0.92319,     0.92313,     0.92306,     0.92299,     0.92293,     0.92286,     0.92279,     0.92273,     0.92266,     0.92259,     0.92253,     0.92246,     0.92239,     0.92233,     0.92226,     0.92219,     0.92213,     0.92206,       0.922,     0.92193,     0.92186,      0.9218,\n",
       "            0.92173,     0.92166,      0.9216,     0.92153,     0.92146,      0.9214,     0.92133,     0.92126,      0.9212,     0.92113,     0.92106,       0.921,     0.92093,     0.92086,      0.9208,     0.92073,     0.92066,      0.9206,     0.92053,     0.92046,      0.9204,     0.92033,     0.92026,\n",
       "             0.9202,     0.92013,     0.92006,     0.91975,     0.91329,     0.90683,     0.90037,     0.89575,     0.89125,     0.88675,     0.88225,     0.87974,     0.87922,      0.8787,     0.87818,     0.87767,     0.87715,     0.87663,     0.87611,     0.87559,     0.87507,     0.87455,     0.87404,\n",
       "            0.87352,       0.873,     0.87248,     0.87196,     0.87144,     0.87092,     0.87041,     0.86989,     0.86937,     0.86885,     0.86833,     0.86781,     0.86729,     0.86678,     0.86626,     0.86574,     0.86522,      0.8647,     0.86418,     0.86366,     0.86315,     0.86263,     0.86211,\n",
       "            0.86159,     0.86107,     0.86055,     0.86003,     0.85913,      0.8582,     0.85727,     0.85633,      0.8554,     0.85447,     0.85354,     0.85261,     0.85167,     0.85074,     0.84981,     0.84888,     0.84795,     0.84701,     0.84608,     0.84515,     0.84422,     0.84328,     0.84235,\n",
       "            0.84142,     0.84049,     0.83598,     0.82753,     0.81944,     0.81428,     0.80912,     0.80396,     0.77924,     0.77252,      0.7658,     0.74234,     0.70804,     0.68406,     0.63787,     0.62506,     0.60494,     0.59303,     0.58434,     0.55055,     0.53497,     0.52622,     0.50337,\n",
       "            0.45289,     0.41643,     0.40844,     0.40046,     0.37326,     0.36321,     0.31828,     0.28954,     0.27739,     0.27043,     0.26348,     0.25741,     0.25222,     0.24704,     0.24185,     0.23339,     0.22311,     0.21682,     0.21226,     0.20771,     0.20315,     0.19764,     0.18997,\n",
       "            0.18231,     0.16362,     0.15866,     0.15708,      0.1555,     0.15391,     0.15233,     0.15075,     0.14916,     0.14758,       0.146,     0.14442,     0.14283,     0.14125,     0.13807,      0.1289,     0.11992,     0.11738,     0.11484,      0.1123,     0.10975,     0.10721,     0.10467,\n",
       "            0.10213,    0.095979,    0.079586,    0.078399,    0.077213,    0.076026,     0.07484,    0.073653,    0.072467,     0.07128,    0.070094,    0.068907,    0.067721,    0.066534,    0.065348,    0.064161,    0.062975,    0.061788,    0.060602,    0.038276,    0.034135,    0.029994,    0.025853,\n",
       "           0.021713,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.8423993147737381\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([     0.8277])\n",
       "names: {0: 'Vedant'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 1.0, 'metrics/recall(B)': 0.9555263010440417, 'metrics/mAP50(B)': 0.9746721311475409, 'metrics/mAP50-95(B)': 0.8277023351766489, 'fitness': 0.8423993147737381}\n",
       "save_dir: WindowsPath('runs/detect/train4')\n",
       "speed: {'preprocess': 0.029383370509514443, 'inference': 16.861974619902096, 'loss': 0.0, 'postprocess': 0.056293721382434554}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trained the model on my face dataset with well labeled - it tooks me around 3h only for 20 epochs :( \n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "model = YOLO(\"yolo11l.pt\")  \n",
    "\n",
    "\n",
    "model.train(data=r\"C:\\Users\\HP\\Desktop\\Machine learning\\custom__dataset\\data.yaml\", epochs=100, imgsz=84, batch=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f40a27-dcfd-4bd0-99ad-8dc5d02b62f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624326b3-585c-437d-92ef-179d53f16bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1/1: 0... Success  (inf frames of shape 640x480 at 30.00 FPS)\n",
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "0: 96x96 1 Vedant, 139.8ms\n",
      "0: 96x96 1 Vedant, 121.0ms\n",
      "0: 96x96 1 Vedant, 102.7ms\n",
      "0: 96x96 1 Vedant, 101.5ms\n",
      "0: 96x96 1 Vedant, 101.0ms\n",
      "0: 96x96 1 Vedant, 95.0ms\n",
      "0: 96x96 1 Vedant, 100.0ms\n",
      "0: 96x96 1 Vedant, 92.0ms\n",
      "0: 96x96 1 Vedant, 93.5ms\n",
      "0: 96x96 1 Vedant, 89.8ms\n",
      "0: 96x96 1 Vedant, 99.8ms\n",
      "0: 96x96 1 Vedant, 84.4ms\n",
      "0: 96x96 1 Vedant, 82.9ms\n",
      "0: 96x96 1 Vedant, 84.0ms\n",
      "0: 96x96 1 Vedant, 92.8ms\n",
      "0: 96x96 1 Vedant, 98.4ms\n",
      "0: 96x96 1 Vedant, 94.8ms\n",
      "0: 96x96 1 Vedant, 101.3ms\n",
      "0: 96x96 1 Vedant, 95.6ms\n",
      "0: 96x96 1 Vedant, 100.5ms\n",
      "0: 96x96 1 Vedant, 97.8ms\n",
      "0: 96x96 1 Vedant, 98.0ms\n",
      "0: 96x96 1 Vedant, 92.8ms\n",
      "0: 96x96 1 Vedant, 96.3ms\n",
      "0: 96x96 (no detections), 90.9ms\n",
      "0: 96x96 (no detections), 98.6ms\n",
      "0: 96x96 (no detections), 91.4ms\n",
      "0: 96x96 (no detections), 97.0ms\n",
      "0: 96x96 (no detections), 92.5ms\n",
      "0: 96x96 (no detections), 93.9ms\n",
      "0: 96x96 (no detections), 92.5ms\n",
      "0: 96x96 (no detections), 88.5ms\n",
      "0: 96x96 (no detections), 99.9ms\n",
      "0: 96x96 (no detections), 98.2ms\n",
      "0: 96x96 (no detections), 93.3ms\n",
      "0: 96x96 1 Vedant, 108.2ms\n",
      "0: 96x96 1 Vedant, 116.6ms\n",
      "0: 96x96 1 Vedant, 83.5ms\n",
      "0: 96x96 2 Vedants, 83.7ms\n",
      "0: 96x96 1 Vedant, 95.7ms\n",
      "0: 96x96 1 Vedant, 95.7ms\n",
      "0: 96x96 1 Vedant, 83.1ms\n",
      "0: 96x96 1 Vedant, 92.0ms\n",
      "0: 96x96 2 Vedants, 120.2ms\n",
      "0: 96x96 2 Vedants, 96.2ms\n",
      "0: 96x96 2 Vedants, 79.5ms\n",
      "0: 96x96 2 Vedants, 87.1ms\n",
      "0: 96x96 2 Vedants, 93.7ms\n",
      "0: 96x96 2 Vedants, 97.4ms\n",
      "0: 96x96 2 Vedants, 81.6ms\n",
      "0: 96x96 2 Vedants, 92.7ms\n",
      "0: 96x96 2 Vedants, 95.5ms\n",
      "0: 96x96 2 Vedants, 94.4ms\n",
      "0: 96x96 2 Vedants, 94.1ms\n",
      "0: 96x96 2 Vedants, 99.8ms\n",
      "0: 96x96 2 Vedants, 83.5ms\n",
      "0: 96x96 2 Vedants, 93.7ms\n",
      "0: 96x96 2 Vedants, 88.5ms\n",
      "0: 96x96 2 Vedants, 83.9ms\n",
      "0: 96x96 1 Vedant, 79.7ms\n",
      "0: 96x96 1 Vedant, 91.2ms\n",
      "0: 96x96 (no detections), 93.8ms\n",
      "0: 96x96 (no detections), 93.2ms\n",
      "0: 96x96 (no detections), 94.3ms\n",
      "0: 96x96 (no detections), 90.6ms\n",
      "0: 96x96 1 Vedant, 92.4ms\n",
      "0: 96x96 (no detections), 92.2ms\n",
      "0: 96x96 (no detections), 89.5ms\n",
      "0: 96x96 1 Vedant, 85.1ms\n",
      "0: 96x96 (no detections), 93.6ms\n",
      "0: 96x96 1 Vedant, 91.0ms\n",
      "0: 96x96 1 Vedant, 93.8ms\n",
      "0: 96x96 1 Vedant, 93.3ms\n",
      "0: 96x96 1 Vedant, 83.4ms\n",
      "0: 96x96 1 Vedant, 92.0ms\n",
      "0: 96x96 1 Vedant, 102.9ms\n",
      "0: 96x96 1 Vedant, 96.2ms\n",
      "0: 96x96 1 Vedant, 99.8ms\n",
      "0: 96x96 1 Vedant, 93.6ms\n",
      "0: 96x96 1 Vedant, 88.1ms\n",
      "0: 96x96 1 Vedant, 95.9ms\n",
      "0: 96x96 1 Vedant, 103.3ms\n",
      "0: 96x96 1 Vedant, 98.0ms\n",
      "0: 96x96 (no detections), 93.1ms\n",
      "0: 96x96 1 Vedant, 96.7ms\n",
      "0: 96x96 1 Vedant, 90.4ms\n",
      "0: 96x96 1 Vedant, 100.6ms\n",
      "0: 96x96 1 Vedant, 94.4ms\n",
      "0: 96x96 1 Vedant, 97.3ms\n",
      "0: 96x96 1 Vedant, 92.1ms\n",
      "0: 96x96 1 Vedant, 98.2ms\n",
      "0: 96x96 1 Vedant, 91.2ms\n",
      "0: 96x96 1 Vedant, 96.3ms\n",
      "0: 96x96 1 Vedant, 96.3ms\n",
      "0: 96x96 1 Vedant, 116.6ms\n",
      "0: 96x96 1 Vedant, 102.3ms\n",
      "0: 96x96 1 Vedant, 98.2ms\n",
      "0: 96x96 1 Vedant, 83.8ms\n",
      "0: 96x96 1 Vedant, 101.6ms\n",
      "0: 96x96 1 Vedant, 93.3ms\n",
      "0: 96x96 1 Vedant, 90.9ms\n",
      "0: 96x96 1 Vedant, 101.9ms\n",
      "0: 96x96 1 Vedant, 97.1ms\n",
      "0: 96x96 1 Vedant, 91.2ms\n",
      "0: 96x96 1 Vedant, 93.4ms\n",
      "0: 96x96 1 Vedant, 99.6ms\n",
      "0: 96x96 1 Vedant, 95.2ms\n",
      "0: 96x96 1 Vedant, 93.8ms\n",
      "0: 96x96 1 Vedant, 96.1ms\n",
      "0: 96x96 1 Vedant, 90.7ms\n",
      "0: 96x96 1 Vedant, 103.0ms\n",
      "0: 96x96 1 Vedant, 97.5ms\n",
      "0: 96x96 1 Vedant, 101.8ms\n",
      "0: 96x96 1 Vedant, 97.3ms\n",
      "0: 96x96 1 Vedant, 100.4ms\n",
      "0: 96x96 1 Vedant, 105.5ms\n",
      "0: 96x96 1 Vedant, 99.0ms\n",
      "0: 96x96 (no detections), 100.2ms\n",
      "0: 96x96 (no detections), 98.1ms\n",
      "0: 96x96 (no detections), 94.7ms\n",
      "0: 96x96 (no detections), 97.4ms\n",
      "0: 96x96 (no detections), 96.6ms\n",
      "0: 96x96 (no detections), 98.6ms\n",
      "0: 96x96 (no detections), 100.1ms\n",
      "0: 96x96 (no detections), 97.6ms\n",
      "0: 96x96 (no detections), 103.9ms\n",
      "0: 96x96 (no detections), 101.2ms\n",
      "0: 96x96 (no detections), 101.0ms\n",
      "0: 96x96 (no detections), 95.3ms\n",
      "0: 96x96 (no detections), 89.2ms\n",
      "0: 96x96 1 Vedant, 81.5ms\n",
      "0: 96x96 (no detections), 99.2ms\n",
      "0: 96x96 1 Vedant, 90.7ms\n",
      "0: 96x96 1 Vedant, 97.1ms\n",
      "0: 96x96 1 Vedant, 96.1ms\n",
      "0: 96x96 1 Vedant, 96.2ms\n",
      "0: 96x96 1 Vedant, 108.6ms\n",
      "0: 96x96 1 Vedant, 112.7ms\n",
      "0: 96x96 1 Vedant, 102.6ms\n",
      "0: 96x96 1 Vedant, 106.6ms\n",
      "0: 96x96 1 Vedant, 102.5ms\n",
      "0: 96x96 1 Vedant, 102.5ms\n",
      "0: 96x96 1 Vedant, 100.6ms\n",
      "0: 96x96 (no detections), 105.0ms\n",
      "0: 96x96 (no detections), 116.2ms\n",
      "0: 96x96 (no detections), 148.3ms\n",
      "0: 96x96 (no detections), 111.5ms\n",
      "0: 96x96 (no detections), 104.9ms\n",
      "0: 96x96 (no detections), 104.2ms\n",
      "0: 96x96 (no detections), 99.8ms\n",
      "0: 96x96 (no detections), 103.5ms\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(r\"C:\\Users\\HP\\Desktop\\Machine learning\\runs\\detect\\train4\\weights\\best.pt\") \n",
    "results = model(source=0,show=True,conf=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7b985a-402d-4def-b9d4-f20dcaec3cef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8c7b4ce-d64c-4c8d-ba27-3e47279b346d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 96x96 1 Vedant, 188.9ms\n",
      "Speed: 1.0ms preprocess, 188.9ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 124.8ms\n",
      "Speed: 1.0ms preprocess, 124.8ms inference, 1.5ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 107.6ms\n",
      "Speed: 2.0ms preprocess, 107.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 99.9ms\n",
      "Speed: 1.5ms preprocess, 99.9ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 94.7ms\n",
      "Speed: 1.1ms preprocess, 94.7ms inference, 2.3ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 110.4ms\n",
      "Speed: 2.0ms preprocess, 110.4ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 112.3ms\n",
      "Speed: 1.1ms preprocess, 112.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 133.9ms\n",
      "Speed: 1.0ms preprocess, 133.9ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 115.2ms\n",
      "Speed: 1.0ms preprocess, 115.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 108.1ms\n",
      "Speed: 2.0ms preprocess, 108.1ms inference, 5.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 104.7ms\n",
      "Speed: 1.0ms preprocess, 104.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 109.9ms\n",
      "Speed: 1.0ms preprocess, 109.9ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 108.6ms\n",
      "Speed: 1.0ms preprocess, 108.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 92.1ms\n",
      "Speed: 2.0ms preprocess, 92.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 95.8ms\n",
      "Speed: 2.0ms preprocess, 95.8ms inference, 1.4ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 95.8ms\n",
      "Speed: 2.0ms preprocess, 95.8ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 101.8ms\n",
      "Speed: 2.0ms preprocess, 101.8ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 99.0ms\n",
      "Speed: 1.0ms preprocess, 99.0ms inference, 1.1ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 109.7ms\n",
      "Speed: 1.0ms preprocess, 109.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 119.3ms\n",
      "Speed: 1.0ms preprocess, 119.3ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 150.3ms\n",
      "Speed: 2.0ms preprocess, 150.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 118.1ms\n",
      "Speed: 2.3ms preprocess, 118.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 105.1ms\n",
      "Speed: 1.0ms preprocess, 105.1ms inference, 1.5ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 122.9ms\n",
      "Speed: 1.0ms preprocess, 122.9ms inference, 2.1ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 120.8ms\n",
      "Speed: 1.0ms preprocess, 120.8ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 126.9ms\n",
      "Speed: 1.0ms preprocess, 126.9ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 179.0ms\n",
      "Speed: 1.0ms preprocess, 179.0ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 155.2ms\n",
      "Speed: 2.0ms preprocess, 155.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 119.5ms\n",
      "Speed: 1.0ms preprocess, 119.5ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 111.2ms\n",
      "Speed: 1.0ms preprocess, 111.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 125.9ms\n",
      "Speed: 2.0ms preprocess, 125.9ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 143.0ms\n",
      "Speed: 2.0ms preprocess, 143.0ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 116.1ms\n",
      "Speed: 1.3ms preprocess, 116.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 137.6ms\n",
      "Speed: 1.4ms preprocess, 137.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 103.1ms\n",
      "Speed: 1.0ms preprocess, 103.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 111.2ms\n",
      "Speed: 1.0ms preprocess, 111.2ms inference, 1.1ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 102.7ms\n",
      "Speed: 2.0ms preprocess, 102.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 102.6ms\n",
      "Speed: 1.5ms preprocess, 102.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 90.1ms\n",
      "Speed: 2.0ms preprocess, 90.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 99.3ms\n",
      "Speed: 2.0ms preprocess, 99.3ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 108.1ms\n",
      "Speed: 2.0ms preprocess, 108.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 94.8ms\n",
      "Speed: 2.0ms preprocess, 94.8ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 93.7ms\n",
      "Speed: 1.4ms preprocess, 93.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 91.8ms\n",
      "Speed: 1.0ms preprocess, 91.8ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 107.3ms\n",
      "Speed: 1.2ms preprocess, 107.3ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 104.1ms\n",
      "Speed: 1.0ms preprocess, 104.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 100.3ms\n",
      "Speed: 1.5ms preprocess, 100.3ms inference, 1.5ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 105.2ms\n",
      "Speed: 1.3ms preprocess, 105.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 104.3ms\n",
      "Speed: 1.0ms preprocess, 104.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 99.4ms\n",
      "Speed: 1.4ms preprocess, 99.4ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 109.7ms\n",
      "Speed: 1.4ms preprocess, 109.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 99.2ms\n",
      "Speed: 1.6ms preprocess, 99.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 103.1ms\n",
      "Speed: 1.0ms preprocess, 103.1ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 100.1ms\n",
      "Speed: 2.0ms preprocess, 100.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 100.7ms\n",
      "Speed: 2.0ms preprocess, 100.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 97.2ms\n",
      "Speed: 2.0ms preprocess, 97.2ms inference, 0.5ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 104.7ms\n",
      "Speed: 2.1ms preprocess, 104.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 101.2ms\n",
      "Speed: 2.0ms preprocess, 101.2ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 108.1ms\n",
      "Speed: 1.0ms preprocess, 108.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 112.0ms\n",
      "Speed: 3.0ms preprocess, 112.0ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 111.9ms\n",
      "Speed: 1.0ms preprocess, 111.9ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 99.2ms\n",
      "Speed: 1.0ms preprocess, 99.2ms inference, 1.1ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 101.1ms\n",
      "Speed: 0.0ms preprocess, 101.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 108.8ms\n",
      "Speed: 1.0ms preprocess, 108.8ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 105.5ms\n",
      "Speed: 2.0ms preprocess, 105.5ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 102.8ms\n",
      "Speed: 1.0ms preprocess, 102.8ms inference, 1.7ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 141.4ms\n",
      "Speed: 1.0ms preprocess, 141.4ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 133.5ms\n",
      "Speed: 1.0ms preprocess, 133.5ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 124.9ms\n",
      "Speed: 2.0ms preprocess, 124.9ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 124.3ms\n",
      "Speed: 1.3ms preprocess, 124.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 119.3ms\n",
      "Speed: 1.5ms preprocess, 119.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 140.5ms\n",
      "Speed: 2.0ms preprocess, 140.5ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 151.0ms\n",
      "Speed: 1.0ms preprocess, 151.0ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 122.6ms\n",
      "Speed: 1.0ms preprocess, 122.6ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 142.2ms\n",
      "Speed: 2.0ms preprocess, 142.2ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 213.5ms\n",
      "Speed: 2.0ms preprocess, 213.5ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 161.3ms\n",
      "Speed: 1.0ms preprocess, 161.3ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 204.8ms\n",
      "Speed: 1.0ms preprocess, 204.8ms inference, 2.5ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 113.3ms\n",
      "Speed: 3.0ms preprocess, 113.3ms inference, 1.4ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 112.2ms\n",
      "Speed: 1.4ms preprocess, 112.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 99.6ms\n",
      "Speed: 1.0ms preprocess, 99.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 99.8ms\n",
      "Speed: 2.1ms preprocess, 99.8ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 99.3ms\n",
      "Speed: 1.0ms preprocess, 99.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 100.1ms\n",
      "Speed: 2.0ms preprocess, 100.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 97.2ms\n",
      "Speed: 2.0ms preprocess, 97.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 102.4ms\n",
      "Speed: 2.0ms preprocess, 102.4ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 108.3ms\n",
      "Speed: 2.5ms preprocess, 108.3ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 119.2ms\n",
      "Speed: 1.0ms preprocess, 119.2ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 146.8ms\n",
      "Speed: 1.0ms preprocess, 146.8ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 109.1ms\n",
      "Speed: 1.0ms preprocess, 109.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 108.3ms\n",
      "Speed: 1.0ms preprocess, 108.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 98.4ms\n",
      "Speed: 1.0ms preprocess, 98.4ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 116.0ms\n",
      "Speed: 1.4ms preprocess, 116.0ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 108.1ms\n",
      "Speed: 2.0ms preprocess, 108.1ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 136.9ms\n",
      "Speed: 1.0ms preprocess, 136.9ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 141.8ms\n",
      "Speed: 2.0ms preprocess, 141.8ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 145.5ms\n",
      "Speed: 1.0ms preprocess, 145.5ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 105.4ms\n",
      "Speed: 1.0ms preprocess, 105.4ms inference, 2.2ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 123.1ms\n",
      "Speed: 1.0ms preprocess, 123.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 133.8ms\n",
      "Speed: 1.0ms preprocess, 133.8ms inference, 2.1ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 145.7ms\n",
      "Speed: 1.0ms preprocess, 145.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 133.2ms\n",
      "Speed: 1.5ms preprocess, 133.2ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 143.4ms\n",
      "Speed: 1.0ms preprocess, 143.4ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 155.1ms\n",
      "Speed: 1.0ms preprocess, 155.1ms inference, 2.5ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 130.0ms\n",
      "Speed: 1.0ms preprocess, 130.0ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 129.9ms\n",
      "Speed: 2.0ms preprocess, 129.9ms inference, 2.1ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 136.5ms\n",
      "Speed: 1.0ms preprocess, 136.5ms inference, 1.5ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 176.9ms\n",
      "Speed: 1.0ms preprocess, 176.9ms inference, 2.4ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 117.6ms\n",
      "Speed: 1.0ms preprocess, 117.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 95.5ms\n",
      "Speed: 1.1ms preprocess, 95.5ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 103.5ms\n",
      "Speed: 1.0ms preprocess, 103.5ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 105.0ms\n",
      "Speed: 1.0ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 93.9ms\n",
      "Speed: 1.0ms preprocess, 93.9ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 112.5ms\n",
      "Speed: 1.0ms preprocess, 112.5ms inference, 1.4ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 98.1ms\n",
      "Speed: 1.3ms preprocess, 98.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 90.9ms\n",
      "Speed: 1.4ms preprocess, 90.9ms inference, 1.8ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 91.3ms\n",
      "Speed: 1.0ms preprocess, 91.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 98.0ms\n",
      "Speed: 1.0ms preprocess, 98.0ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 95.6ms\n",
      "Speed: 1.0ms preprocess, 95.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 102.4ms\n",
      "Speed: 2.0ms preprocess, 102.4ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 95.8ms\n",
      "Speed: 2.0ms preprocess, 95.8ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 98.0ms\n",
      "Speed: 2.0ms preprocess, 98.0ms inference, 1.4ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 98.4ms\n",
      "Speed: 1.0ms preprocess, 98.4ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 98.5ms\n",
      "Speed: 2.0ms preprocess, 98.5ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 94.0ms\n",
      "Speed: 2.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 95.2ms\n",
      "Speed: 1.2ms preprocess, 95.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 99.7ms\n",
      "Speed: 0.0ms preprocess, 99.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 92.8ms\n",
      "Speed: 1.0ms preprocess, 92.8ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 113.6ms\n",
      "Speed: 2.1ms preprocess, 113.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 89.8ms\n",
      "Speed: 1.0ms preprocess, 89.8ms inference, 2.4ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 92.2ms\n",
      "Speed: 1.0ms preprocess, 92.2ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 99.4ms\n",
      "Speed: 1.0ms preprocess, 99.4ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 96.5ms\n",
      "Speed: 1.4ms preprocess, 96.5ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 95.8ms\n",
      "Speed: 2.0ms preprocess, 95.8ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 105.1ms\n",
      "Speed: 1.0ms preprocess, 105.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 97.2ms\n",
      "Speed: 1.0ms preprocess, 97.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 89.7ms\n",
      "Speed: 1.0ms preprocess, 89.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 87.4ms\n",
      "Speed: 1.2ms preprocess, 87.4ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 100.8ms\n",
      "Speed: 2.0ms preprocess, 100.8ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 91.8ms\n",
      "Speed: 0.0ms preprocess, 91.8ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 89.9ms\n",
      "Speed: 1.0ms preprocess, 89.9ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 80.7ms\n",
      "Speed: 1.0ms preprocess, 80.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 108.0ms\n",
      "Speed: 1.0ms preprocess, 108.0ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 2 Vedants, 92.7ms\n",
      "Speed: 1.0ms preprocess, 92.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 90.7ms\n",
      "Speed: 1.0ms preprocess, 90.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 85.8ms\n",
      "Speed: 1.0ms preprocess, 85.8ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 90.0ms\n",
      "Speed: 1.1ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 83.6ms\n",
      "Speed: 1.2ms preprocess, 83.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 86.2ms\n",
      "Speed: 1.0ms preprocess, 86.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 97.1ms\n",
      "Speed: 1.0ms preprocess, 97.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 92.7ms\n",
      "Speed: 1.0ms preprocess, 92.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 94.9ms\n",
      "Speed: 1.5ms preprocess, 94.9ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 96.1ms\n",
      "Speed: 1.0ms preprocess, 96.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 97.6ms\n",
      "Speed: 1.0ms preprocess, 97.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 104.6ms\n",
      "Speed: 1.0ms preprocess, 104.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 90.0ms\n",
      "Speed: 1.1ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 89.7ms\n",
      "Speed: 1.0ms preprocess, 89.7ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 90.1ms\n",
      "Speed: 1.0ms preprocess, 90.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 115.6ms\n",
      "Speed: 1.0ms preprocess, 115.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 2 Vedants, 91.0ms\n",
      "Speed: 2.3ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 82.4ms\n",
      "Speed: 1.0ms preprocess, 82.4ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 96.8ms\n",
      "Speed: 1.3ms preprocess, 96.8ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 94.6ms\n",
      "Speed: 1.0ms preprocess, 94.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 85.5ms\n",
      "Speed: 2.0ms preprocess, 85.5ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 92.5ms\n",
      "Speed: 1.5ms preprocess, 92.5ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 123.6ms\n",
      "Speed: 1.0ms preprocess, 123.6ms inference, 1.3ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 95.4ms\n",
      "Speed: 1.0ms preprocess, 95.4ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 92.2ms\n",
      "Speed: 1.2ms preprocess, 92.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 92.5ms\n",
      "Speed: 1.4ms preprocess, 92.5ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 2 Vedants, 91.1ms\n",
      "Speed: 1.0ms preprocess, 91.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 2 Vedants, 89.8ms\n",
      "Speed: 1.0ms preprocess, 89.8ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 2 Vedants, 94.8ms\n",
      "Speed: 0.0ms preprocess, 94.8ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 3 Vedants, 89.4ms\n",
      "Speed: 1.0ms preprocess, 89.4ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 3 Vedants, 88.0ms\n",
      "Speed: 1.3ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 3 Vedants, 96.8ms\n",
      "Speed: 1.0ms preprocess, 96.8ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 2 Vedants, 94.9ms\n",
      "Speed: 1.0ms preprocess, 94.9ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 2 Vedants, 110.5ms\n",
      "Speed: 1.0ms preprocess, 110.5ms inference, 2.1ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 90.3ms\n",
      "Speed: 2.0ms preprocess, 90.3ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 2 Vedants, 94.4ms\n",
      "Speed: 1.3ms preprocess, 94.4ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 99.6ms\n",
      "Speed: 2.6ms preprocess, 99.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 2 Vedants, 95.3ms\n",
      "Speed: 1.0ms preprocess, 95.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 94.1ms\n",
      "Speed: 1.0ms preprocess, 94.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 101.3ms\n",
      "Speed: 2.0ms preprocess, 101.3ms inference, 1.5ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 103.3ms\n",
      "Speed: 1.0ms preprocess, 103.3ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 3 Vedants, 94.8ms\n",
      "Speed: 1.0ms preprocess, 94.8ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 1 Vedant, 96.2ms\n",
      "Speed: 1.0ms preprocess, 96.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 2 Vedants, 111.6ms\n",
      "Speed: 1.0ms preprocess, 111.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 96)\n",
      "\n",
      "0: 96x96 3 Vedants, 100.0ms\n",
      "Speed: 2.0ms preprocess, 100.0ms inference, 1.5ms postprocess per image at shape (1, 3, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "#But wait was worth as it was detecting my face perfectly and for unknow person my model was not even detecting them :)\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "model = YOLO(r\"C:\\Users\\HP\\Desktop\\Machine learning\\runs\\detect\\train11\\weights\\best.pt\") \n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    \n",
    "    results = model(frame)\n",
    "\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0]) \n",
    "            conf = box.conf[0]  \n",
    "            cls = int(box.cls[0])  \n",
    "            \n",
    "            if cls == 0:  \n",
    "                label = f\"VEDANT ({conf:.8f})\"\n",
    "                color = (0, 255, 0) \n",
    "                \n",
    "            else:  \n",
    "                label = \"Unknown\"\n",
    "                color = (0, 0, 255)  \n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    cv2.imshow(\"Face Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11848003-6ac1-4428-a357-ea85eeb1e0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ah, I see what’s happening — and this is a **very common misunderstanding** when working with single-class object detection in YOLO.\n",
    "\n",
    "# Let me break it down and explain why YOLOv11 is **predicting everyone as \"you\"** in real time:\n",
    "\n",
    "# ---\n",
    "\n",
    "# ## ⚠️ Problem:\n",
    "\n",
    "# You trained the model with **only one class**, and that class is labeled with your name (e.g., `\"Vedant\"`). So the model **learns to detect all humans (or people-like features)** as instances of class `\"Vedant\"` — even if they're not you.\n",
    "\n",
    "# ---\n",
    "\n",
    "# ## ✅ Why This Happens:\n",
    "\n",
    "# * YOLO is an **object detector**, not an identity recognition model.\n",
    "# * It doesn't know what \"Vedant\" means — it's just a class label.\n",
    "# * If the training data includes **multiple people**, and all are labeled as `\"Vedant\"`, the model **generalizes** that \"any person = Vedant\".\n",
    "\n",
    "# This leads to:\n",
    "\n",
    "# > **High mAP**, but **incorrect semantic meaning** — because it’s detecting people accurately, just not *you specifically*.\n",
    "\n",
    "# ---\n",
    "\n",
    "# ## 🛠️ How to Fix It\n",
    "\n",
    "# ### Option 1: Use Face Recognition Instead\n",
    "\n",
    "# If your goal is to detect *yourself* specifically (and not just any person), you need to use **face recognition**, not object detection.\n",
    "\n",
    "# 🔧 Tools like:\n",
    "\n",
    "# * `face_recognition` Python library\n",
    "# * `DeepFace` or `InsightFace`\n",
    "# * Combine with YOLO for **\"who is it\" + \"where are they\"**\n",
    "\n",
    "# 📌 YOLO = **where is the person?**\n",
    "# 📌 Face recognition = **who is the person?**\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### Option 2: Multi-class YOLO (Not Ideal for Identity)\n",
    "\n",
    "# If you want to stick with YOLO, you'd need:\n",
    "\n",
    "# * Class 0: Vedant\n",
    "# * Class 1: Not Vedant (others)\n",
    "\n",
    "# This would require **manually labeling** yourself vs others in every image.\n",
    "\n",
    "# But even then, YOLO is not great at **identity recognition** — it will pick up posture, color, or face shape at best.\n",
    "\n",
    "# ---\n",
    "\n",
    "# ### Option 3: Two-Stage Pipeline (Recommended)\n",
    "\n",
    "# Combine both methods:\n",
    "\n",
    "# 1. **YOLOv11** detects all people (bounding boxes).\n",
    "# 2. Inside each box, crop and run **face recognition** to check if it’s you.\n",
    "\n",
    "# This is accurate and scalable.\n",
    "\n",
    "# ---\n",
    "\n",
    "# ## 🚀 Summary\n",
    "\n",
    "# | Goal                            | Recommended Approach             |\n",
    "# | ------------------------------- | -------------------------------- |\n",
    "# | Detect people                   | YOLO (single class: person)      |\n",
    "# | Detect only you                 | Face recognition                 |\n",
    "# | Detect everyone & identify them | YOLO + face recognition pipeline |\n",
    "\n",
    "# ---\n",
    "\n",
    "# Let me know if you want a quick code example for that YOLO + face recognition combo — it's very doable!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
